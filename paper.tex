% ACM
%\documentclass[sigconf]{acmart}

% Manuscript
\documentclass[10pt,twocolumn]{article}
\usepackage[numbers]{natbib}

\usepackage{booktabs} % For formal tables

% Document-specific packages
\usepackage{epigraph}
\usepackage[flushleft]{threeparttable}

% Document-specific definitions
\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}}
\newcommand{\+}{\phantom{-}}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\acmDOI{10.475/123_4}

% ISBN
%\acmISBN{123-4567-24-567/08/06}

%Conference
%\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
%  Paso, Texas USA} 
%\acmYear{1997}
%\copyrightyear{2016}

%\acmPrice{15.00}

\begin{document}
\title{Network Structure, Efficiency, and Performance in WikiProjects}

% ACM
%\author{Edward L. Platt}
%\affiliation{%
%  \institution{University of Michigan}
%  \city{Ann Arbor} 
%  \state{Michigan} 
%}
%\email{elplatt@umich.edu}

% Manuscript
\author{Edward L. Platt \\ University of Michigan \\ Ann Arbor, Michigan \\ elplatt@umich.edu}

% The default list of authors is too long for headers}
%\renewcommand{\shortauthors}{B. Trovato et al.}


% ACM
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%\end{CCSXML}

% ACM
%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}


% ACM
% \keywords{collaboration, peer production, wikipedia}


\maketitle

\begin{abstract}
TODO
\end{abstract}

\section{Introduction}
\epigraph
{The problem with Wikipedia is that it only works in practice. In theory, it can never work.}
{Miikka Ryokas \cite{cohen_latest_2007} }

Wikipedia successful decentralized.

Efficiency Performance

Coeditor network

NK Simulations

Contributions

\section{Background and Related Work}

In the field of social learning,
much research has been done to understand how groups of agents
can solve problems collaboratively.
In {\em networked social learning}, agents are represented by nodes on a network
and can only interact with their neighbors.
Social learning tasks can be divided into cases where agents have {\em generated signals}
(independently noisy estimates of a true value)
and those where agents have {\em interpreted signals}
(solutions based on different internal models of available data)
\cite{hong_interpreted_2009}.
For generated signals,
a naive Bayesian approach converges to the truth when conditions
on the network's degree distribution,
while the speed of convergence depends on the {\em spectral gap}
between the two largest eigenvalues of the network's adjacency matrix
\cite{golub_naive_2010}.
Complex social learning tasks can also be modeled as the problem
of maximizing an objective function with many local maxima,
referred to as a {\em rugged landscape}
\cite{lazer_network_2007, mason_propagation_2008, mason_collaborative_2012, grim_scientific_2013, barkoczi_social_2016}.
Numerical simulations have shown ttht efficient networks (those with short paths between nodes)
can allow less exploration of possible solutions,
resulting in a fast convergence to a non-optimal solution \cite{mason_propagation_2008, grim_scientific_2013}.
However, when conformity-based social learning strategies are used, efficient networks can outperform
inefficient ones \cite{barkoczi_social_2016}.

Lab-based experiments on networked collaboration
suggest a complex interaction between network topology,
and other factors.
While groups of networked human subjects reliably perform very well on
difficult graph-coloring tasks, the best performing network architectures
(e.g., fully-connected vs. small-world) vary
from task to task \cite{kearns_experiments_2012}.
The same studies found that while human subjects tend to perform very well on
a number of networks, they perform worst on collaboratively self-organized
networks, highlighting the importance of intentionality
in constructing communication channels for collective decision-making.
Similarly, some network topologies are able to reach faster decisions in the
presence of more information, while others show the opposite effect
\cite{kearns_experimental_2006}.
Based on lab experiments, Fowler and Christakis \cite{fowler_cooperative_2010}
suggest that individual decisions towards altruism are conditional on their
neighbor's behavior and ``contagious'' up to three degrees away.
Later experiments by Suri and Watts \cite{suri_cooperation_2011} confirmed the
existence of conditional altruism,
but conlcuded that altruistic
behavior only influences first-degree neighbors.

Collaboration as decision-making
Collaboration as consensus

Collaboration as community
Collaboration and social capital

Collaboration on Wikipedia

This project

Wikipedia

OLD STUFF BELOW HERE



Collaboration has also been studied extensively through the lens of collective
decision-making and voting theory.
The Condorcet jury theorem and its extensions \cite{list_epistemic_2001}
describe how individuals can use majority voting to improve their
decision-making ability.
The process of decision-making is sometimes divided into
``talking'' and ``voting'' stages.
While heirarchical representative democracy sometimes improves the outcome
of ``talk,'' it weakens the result of the Condoret jury theorem for voting
\cite{list_epistemic_2001}.
Robert Michels proposed the ``iron law of oligarchy,''
\cite{michels_political_1999} which states that
the earlier members of a group will, over time, gain disproportionate
decision-making power and act increasingly out of self-interest rather than
the good of the group.
Shaw and Hill found that behavior in online wiki communities is consistent
with the iron law \cite{shaw_laboratories_2014}.

A number of studies, summarized in \cite{gentry_consensus_1982},
have examined consensus-based decision-making procedures, used extensively by
the Quakers and later by activist communities.
The hallmark of consensus is the equal and active participation by all members
of a group.
Key findings include the tradeoff between speed and quality of decisions,
the importance of expressing conflict early in the process,
and the willingness to recognize when one's own views are counter to the
existing consensus.
The details of why this tradeoff occurs remain an open question.
De Tar created InterTwinkles \cite{detar_intertwinkles:_2013},
an online suite of tools to facilitate consensus decision-making
in small cooperatives.
With a better understanding of how large-scale network structure influences
decision-making, such tools could be extended to large collaborations.

Research on digital communities has also examined some non-network factors
influcencing the quality of decisions and collaborative work.
Using a simulation model, Hong and Page \cite{hong_groups_2004} found that
diverse groups can outperform groups composed of the best individual
problem-solvers.
A similar result was observed on Wikipedia by
Robert and Romero, who found that
larger group sizes yield higher article ratings
(as determined by editor peer-review)
when the groups are diverse and experienced
\cite{robert_when_2015}.
Also on Wikipedia,
Kittur and Kraut found that different types of coordination have a complex
effect on the quality of Wikipedia articles \cite{kittur_harnessing_2008}.
Both explicit and implicit coordination result in higher quality articles,
with explicit coordination being especially central in the early life of an
article.

In sociology and anthropology, it has often been observed that an individual's
position within a social network can result in privilege or power relative to
others.
For example, powerful individuals are often ``brokers''
who act as exclusive intermediaries between disconnected portions of the
social network \mbox{\cite{silverman_patronage_1965}}.
Similarly, successful innovation in organizations often occurs in ``structural
holes'' between groups \mbox{\cite{granovetter_strength_1973}}.
Thus, the structure of a social network might encode meaningful information
about the distribution of power and social capital within a group.
This \mbox{\em strucural (in)equality} might have important consequences for the
ability of a group to collaborate.
There is some evidence that groups with high structural inequality,
as evidenced by highly-skewed degree distributions,
perform worse on colaborative tasks \mbox{\cite{kearns_experiments_2012}}.

Across the broad range of work on collaboration and related topics,
a few key themes emerge.
The efficiency and performance of collaborations are important considerations
and vary between different networks and problem types.
While social learning predicts no relationship between the two,
contagion-style innovation models predict a tradeoff.
Such a tradeoff has been observed in networked problem-solving and in
different forms of group decision-making.

In this project, I will investigate several gaps in the existing literature.
In most cases, degree distribution seems to correlate to performance.
But aside from the naive Bayes case in social learning, it is unkown whether
the correlation is explained best by degree or by another structural property
correlated with degree.
The characteristic path length and min-cut studied here are candidates for such
degree-correlated factors.
While existing work has focused on families of artificial networks,
this project examines a large number of naturally-occuring networks.
Unlike artificial networks, the structural properties of these naturally-occuring
networks can vary independently, making it easier to isolate individual
network properties that correlate with outcome variables.
This project will also test whether the detrimental effects of skewed
distributions of network properties that have been observed in lab experiments
\mbox{\cite{kearns_experiments_2012}}
can be observed in large-scale, naturally-occuring data.

\section{WikiProjects}

\subsection{Data}

Our analysis combines multiple datasets from the English-language Wikipedia.
For information about edit history, we used a publicly-available dataset containing
metadata about all edits between TODO.
To get the rating history of each article,
we wrote a script to scrape the daily logs produced by WP 1.0 Bot for each WikiProject
between TODO.
Finally, we used a publicly-available log of page events (including rename events)
to reconstruct the unique identifier for each article title mentioned in the rating history logs.

\subsection{Efficiency and Performance}

To model the relationship between performance, efficiency, and network structure,
we must have a way to quantify performance and efficiency.
We define these quantities on a per-WikiProject basis to enable comparisons across different
projects.
Our definitions are inpsired by work modeling collective problem-solving as an optimization
problem \cite{lazer_network_2007, mason_propagation_2008, mason_collaborative_2012,
grim_scientific_2013, barkoczi_social_2016}.
The efficiency quantifies how quikly a solution is reached,
while the performance quantifies how good the eventual solution is.

For a WikiProject, efficiency quantifies how quickly project participants can improve the
assessed quality of an article.
Quality assessments are made through consensus of the project participants themselves,
so different projects can have different standards and practices for assessing article quality.
So the efficiency is not a measure of how quickly some objective measure of quality improves,
but rather of how quickly the project participants can reach consensus on the improvments that
need to be made and make those improvements.
Because our definition relies on assessment transitions, we define efficiency variables for
each of the project-level quality assessments: A, B, and C.
If $T(W,G)$ is the set of transitions in project $W$ from below grade $G$ to grade $G$ (or higher),
then we quantify the efficiency $E(W,G)$ as:
\beq
E(W,G) &=& \sum_{t \in W(P,G)} \left[ \frac{r(t)}{g(t)} \right]^{-1},
\eeq
where $r(t)$ is the number of revisions since the previous grade transition,
and $g(t)$ is the number of grade levels crossed by transition $t$.
The $g(t)$ term is added because an assessments often raise article quality by several
grades, in which case the revisions are divided evenly between all grade levels achieved.
It is also worth noting that we measure efficiency in terms of revisions made,
rather than time passed.
We focus on revisions because the amount of work done on an article varies widely from day to day.

For performance, we wish to quantify how good articles tend to be when they reach a stable state.
Measuring performance is difficult for several reasons:
there is no objective meaasure of article quality avaialbe,
and articles are always changing, making it difficult to know which articles should be considered
complete or stable.
We use an extremely simple performance measure that gives surprisingly consistent results.
In addition to per-project quality assessment, articles can be given ``featured article'' or
``good article'' status.
The criteria for these statuses are consistent across all of Wikipedia,
and any editor can participate in the discussion and decision to award good or featured
status.
In other words, the good and featured statuses are more objective than per-project assessments.
Our performance measure $P(W)$ is just the percentage of articles in project $W$ which have reached
good or featured status:
\beq
P(W) &=& \frac{f(W) + g(W)}{n(W)},
\eeq
where $f(W)$ and $g(W)$ are the numbered of featured and good articles respectively,
and $n(W)$ is the total number of articles.

\subsection{Coeditor Networks}

For each WikiProject, we compare the efficiency and performance measures to the structural
properties of its coeditor network.
The {\em coeditor network} of a WikiProject consists of nodes representing editors.
Two editors are connected when they have both edited the same article or talk page.
The edges are directed, with the direction representing the direction of
{\em plausible information flow};
an edge from editor A to editor B exists if A edited an article and then B edited the same article at
a later time.
Edges can exist in both directions e.g., if an article was edited first by A, then by B, and again by A.
For simplicity, we assign all edges unit weight.
We focus on three structural properties: degree, characteristic path length, and min-cut.

The node degree distribution is the simplest structural property we analyze for WikiProject
coeditor networks.
The in-degree (out-degree) of a node is the number of edges to (from) that node.
Taking the average of either in-degree or out-degree gives the same value:
the {\em mean degree} of the network.
In our context, the mean degree represents how many others a given editor has collaborated with.
We also consider the {\em skewness} of the in-degree and out-degree distributions.
A large positive degree skewness value for a WikiProject coeditor network
implies that a small number of editors have a very large number of collaborators,
while a small positive value implies that the editors having the most collaborators
don't have many more than a typical editor.

We also calculate the characteristic path length for each WikiProject coeditor network.
The {\em distance} from editor A to editor B is the length of the shortest path from A to B.
The {\em characteristic path length} is the mean distance between all editor pairs.
If no path exists between two editors, we exclude that pair from the mean.
For brevity, we will simply refer to this quantity as the {\em path length}.
The path length represents how quickly information can move through the network.
Networks with longer paths require more interactions for information to propagate through
the network,
which has been shown to reduce efficiency in some settings
\cite{mason_propagation_2008,barkoczi_social_2016}.

Our final network measure quantifies the connectivy of a project's coeditor network using
min-cut size.
The minimum $st$-cut between nodes $s$ and $t$ is the set of edges that must be removed in order that
no path exists from $s$ to $t$.
The minimum cut (min-cut) of a graph is the smallest minimum $st$-cut over all node pairs $st$. 
The size of the graph min-cut quantifies the connectivity of a graph,
but only incorporates information about edges lying on paths crossing the min-cut.
Instead, we use the mean size of all minimum $st$-cuts, which we refer to as the
{\em mean min-cut}.
This measure quantifies the number of redundant paths information can take through the network.
Networks with higher redundancy are more resilient to errors on one path \cite{albert_error_2000}
and allow innovations to propagate through complex contagion,
in which innovations are only adopted after multiple exposures thorugh different sources
\cite{centola_complex_2007}.

The mean path and min-cut network measures are computationally intensive,
requiring distance and minimum $st$-cut calculations for each all node pairs.
For larger projects, these calculations are impractical.
When coeditor networks were large, we employed sampling to determine mean path length and mean
min-cut.
For mean path length, source nodes were sampled, and path length was calculated to all destination nodes
from each of these.
For min-cut, node pairs were sampled.
In both cases, stratification was used to ensure the same number of nodes were were sampled from each of
12 node degree quantiles.
We estimated the error due to sampling by determining true values for a medium-sized project,
and calculating error as a function of sample-size.
Sample sizes were chosen such that relative error was below 10\%.
Even with sampling, however, it was impractical to calculate these properties for the largest projects,
so we exclude them from the analysis.
To control for bias in project size, we include several size-related variables in our models.

\subsection{Regression Models}

We model performance and efficiency in WikiProjects using ordinary least-squares linear regression.
Each WikiProject is taken as a single observation.
The models include each project's coeditor network properties as independent variables.
We also include several project-level variables to control for confounding factors.
The C-efficiency is included in the model for performance to control for the presence of articles
that are actively being improved.
Projects with lower efficiency will have more works-in-progress and could have an artifically low
performance without controlling for efficiency.
Some variables are log-transformed to reduce heteroscedasticity.

Our models are summarized in Table \ref{tab:model}.
Mean min-cut was found to be highly correlated with degree (see Figure \ref{fig:degree-mincut}),
so we exclude min-cut to prevent collinearity.
The high correlation between mean degree and min-cut implies that in most cases
the minimum $st$-cut is simply the either set of edges from $s$ or the set of edges to $t$.
The rarity of non-trivial min-cuts suggests that WikiProject coeditor networks have very few central
bottlenecks and are thus highly decentralized.
In-degree and out-degree skewness were also highly correlated, so each dependent variable was modelled twice:
once with in-degree skewness and once with out-degree skewness.

The regression results are consistent whether in-degree or out-degree skewness is used,
although the out-degree models are slightly more significant when modelling efficiency.
We also see that B-efficiency and C-efficiency have very similar models, but that A-efficiency behaves
differently in its dependence on degree skewness and connectivity.
The different behavior of A-efficiency is likely explained by the observation that the A-Class quality is
infrequently used in practice, meaning that the quality level is usually achieved when an article is rated
as a good or featured article, which involves a different consensus process than lower ratings.

The negative dependence of performance on C-efficiency suggests there is generally a tradeoff between
performance and efficiency.
However, low degree is correlated with both higher efficiency and higher performance,
suggesting that it is sometimes possible to improve both simultaneously.
Much of the existing numerical work on networked social learning focuses on path length rather than degree,
so we explore this result further using simulations in the next section.

For path length, we find that longer lengths correspond to lower performance, contrary to the conjecture
that longer path lengths allow more exploration \cite{mason_propagation_2008}
but consistent with a conformity-based social learning strategy \cite{barkoczi_social_2016}.

We also observe that high degree skewness is correlated with lower performance and lower A-efficiency,
suggesting that articles in projects with decentralized coeditor networks reach featured or good status
more efficiently, and reach higher quality ratings in general.

\begin{figure}
\caption{
TODO
\label{fig:degree-mincut}
}
\end{figure}

\begin{table*}
\small
\begin{tabular}{lllllllll}
                               & Perf$^\dagger$ & Perf$^\dagger$ & A-Eff$^\dagger$ & A-Eff$^\dagger$ & B-Eff$^\dagger$ & B-Eff$^\dagger$ & C-Eff$^\dagger$ & C-Eff$^\dagger$ \\
\hline
Mean degree$^\dagger$          &  -0.84$^{***}$  &  -0.78$^{***}$
                               &  -0.61$^{**}$   &  -0.84$^{***}$
                               &  -0.50$^{***}$  &  -0.61$^{***}$
                               &  -0.34$^{**}$   &  -0.31$^{*}$ \\
In-degree skewness$^\dagger$   &  -0.58$^{***}$  & \+ ---      
                               &  -0.43$^{**}$   & \+ ---      
                               &  -0.19          & \+ ---      
                               &  -0.1           & \+ ---      \\
Out-degree skewness$^\dagger$  &  \+ ---         &  -0.48$^{***}$  
                               &  \+ ---         &  -0.57$^{***}$
                               &  \+ ---         &  -0.26$^{*}$
                               &  \+ ---         &  -0.066 \\
Mean path$^\dagger$            &  -0.357$^{***}$ &  -0.356$^{***}$ 
                               &  -0.026         &  -0.096
                               &  -0.020         &  -0.045
                               &  -0.092$^{**}$  &  -0.086 \\
C-eff$^\dagger$                &  -0.083$^{**}$  & -0.085$^{**}$  
                               &  \+ ---         & \+ ---      
                               &  \+ ---         & \+ ---      
                               &  \+ ---         & \+ --- \\
Connectivity                   & \+0.018         & \+0.016        
                               & \+0.081         & \+0.088
                               & \+0.126$^{***}$ & \+0.142$^{***}$
                               & \+0.080$^{**}$  & \+0.081$^{**}$ \\
Mean editors/article$^\dagger$ & \+0.37$^{***}$  & \+0.40$^{***}$ 
                               & \+0.22          & \+0.27
                               & \+0.20          & \+0.22$^{*}$
                               & \+0.076         & \+0.075 \\
Article count$^\dagger$        &  -0.32          & -0.27          
                               & \+0.63${^*}$    & \+0.70${^*}$ 
                               & \+0.76$^{**}$   & \+0.78$^{**}$
                               & \+0.67$^{***}$  & \+0.67$^{***}$ \\
Editor count$^\dagger$         & \+0.68$^{*}$    & \+0.48         
                               & \+0.74$^{*}$    & \+0.97$^{**}$
                               & \+0.60$^{*}$    & \+0.72$^{**}$
                               & \+0.52$^{*}$    & \+0.46$^{*}$ \\
Revision count$^\dagger$       & \+0.37          & \+0.39         
                               &  -0.84$^{**}$   & -0.88$^{**}$
                               &  -1.05$^{***}$  & -1.05$^{***}$
                               &  -1.00$^{***}$  & -1.00$^{***}$ \\
First assessment               & \+0.028         & \+0.058        
                               & \+0.086$^{*}$   & \+0.101$^{**}$
                               & \+0.309$^{***}$ & \+0.321$^{***}$
                               & \+0.456$^{***}$ & \+0.460$^{***}$ \\
Mean article age               &  -0.040         & -0.029         
                               &  -0.049         & -0.037
                               &  -0.019         & -0.014
                               &  -0.046$^{*}$   & -0.045$^{*}$ \\
\hline
DoF                            & 1278            & 1278          
                               & 1048            & 1048
                               & 1371            & 1371
                               & 1540            & 1540 \\
R$^2_{adj}$                    & 0.37            & 0.37          
                               & 0.15            & 0.16
                               & 0.30            & 0.30
                               & 0.43            & 0.43 \\
\end{tabular}
\caption{Standardized coefficients for OLS models.
\label{tab:model}
}
\begin{tablenotes}
\item $\dagger$ Log-transformed. * $p < 0.05$. ** $p < 0.01$. *** $p < 0.001$.
\end{tablenotes}
\end{table*}

\section{Numerical Simulations}

We use numerical simulations to determine whether simple models can reproduce the behavior we
observe in WikiProject coeditor networks.
Following existing numerical work on networked social learning
\cite{lazer_network_2007, mason_propagation_2008, mason_collaborative_2012, barkoczi_social_2016},
we use the NK model \cite{kauffman_towards_1987} to create NP-hard, nonlinear optimization problems
and evaluate the effects of network structure and learning strategy on a group's ability to
find solution to those problems.
We are particularly interested in the effect of degree on the efficiency and performance of a group
of networked problem-solving agents.

In the NK model, N loci each have a binary state and value determined by a random lookup table mapping its state
and the state of another K loci to a real number in $[0,1]$.
We report results for the case $N=250$, $K=7$.
Solutions thus take the form of an N-bit string, and the value of the solution is the mean over all loci values.

For a particular problem-solving trial, agents each store their current favored solution and
apply learning strategies to iteratively improve those solutions. We define their
efficiency and performance in terms of the mean solution values for each time step.
We define the performance to be the mean solution value after the process has converged,
while the efficiency is the reciprocal of the number of steps required to converge.
We measure the time to convergence as the number of steps required to reach 99\% of the maximum
mean solution value.

\subsection{Learning Strategies}

Agents can engage in individual learning by applying a hill-climbing algorithm to their current solution.
In each iteration, one bit of the NK solution string is flipped to maximize the solution value.
If no change improves the value, the original solution is kept.
Agents can also incorporate information from any other agents they are connected to by a network edge.
While individual learning always converges to the local maximum relative to the starting point,
social learning strategies allow agents to ``jump'' to drastically different solutions with higher local maxima.

We use both the conformity and best-neighbor strategy from \cite{barkoczi_social_2016}.
In the {\em best-neighbor} strategy, each agent compares its solution to the those of all its
neighbors, and chooses the solution with the highest value.
In the {\em conformity} strategy, agents simply choose the most common solution among their neighbors
(ties are broken uniformly at random).
In both cases, a single iteration of individual learning is performed after each social learning
iteration.

We introduce a new strategy, which we call the consensus strategy.
In {\em consensus}, agents first apply individual learning.
Next, a consensus solution is constructed from each agent's individual solution by setting
each NK locus's state to its most common value among the agent's individual solutions.
The result of this process is that agents accept a single consensus solution at each iteration,
which forms the basis for future individual learning.
We include this strategy because of its similarity to the editing process of Wikipedia:
at any given time, a Wikipedia article has a single state, determined by consensus,
but editors may have differing opinions on how to improve that article.

We also introduce local variants of the above strategies.
The local variants are meant to reflect a more realistic collaboration setting where
individual agents focus on sub-problems.
In these variants, individual learning takes place on a subset of NK loci.
Each agent is associated with an NK locus and the loci its value depends on.
These loci are the agent's {\em concern},
and are the only ones used for individual learning.
Similarly, in the consensus strategy, an NK locus's value is determined only by the agents
concerned with that locus, rather than all agents.

\subsection{Network family}

The agent networks used in our simulations vary from those in previous work in two important ways:
they reflect the structure of the NK model being optimized,
and they allow the degree to be tuned with minimal change to the mean path length.

Our networks are generated by first creating an agent node for each NK locus.
Each node is assigned a concern consisting of its associated locus and all loci its value depends on,
as in the local learning strategies.
This procedure forms an agent-locus affiliation network.
Next, an agent-agent co-affiliation network is created by connecting two agents if they share at least
one locus in their concerns.
This process is exactly analagous to our definition of a WikiProject coeditor network,
with agents playing the role of editors and NK loci playing the role of Wikipedia articles.

To create a tunable degree, we duplicate each node and its node-locus edges and then
randomly rewire those edges before creating the agent-agent netowork.
The duplication process creates a high overlap between agent concerns,
meaning that most agent-locus edges are redundant and do not create additional agent-agent edges,
resulting in a low average degree.
By randomly rewiring the agent-locus edges, the redundancy is reduced and the average degree of
the agent-agent network is increased.

\subsection{Simulation results}

TODO

\section{Discussion}
TODO

\section{Conclusion}
TODO

\section{Acknowledgements}
I would like to thank Daniel Romero for valuable guidance and feedback;
Danielle Livneh and Karthik Ramanathan for help collecting the data sets;
Yan Chen and Tanya Rosenblat for feedback on the methodology;
and the atendees of the May 25, 2017 MIT Center for Civic Media lab meeting and
the Berkman-Klein Center's Cooperation Working Group for helpful feedback on
preliminary results.
This research was funded by the University of Michigan School of Information.

% ACM
%\bibliographystyle{ACM-Reference-Format}

% Manuscript
\bibliographystyle{acm}

\bibliography{paper} 

\end{document}
