Collective action can empower individuals with limited resources by allowing them to pool those resources with others to achieve common goals. To achieve those goals however, individuals must be able to cooperate. Cooperation requires both that individuals can agree on which actions they should take, and that they can coordinate any information necessary to execute those actions effectively. Both collective decision-making and coordination fall under the category of collective intelligence. This chapter reviews work on both collective action and collective intelligence, and discusses how the latter can inform the former.

No unified theory or framework of collective action exists (Ostrom, 2000). For the purpose of this review, I will adopt a framework consisting of four stages: ideation, deliberation, decision-making, and execution (Figure 1). These stages are roughly sequential, but represent a simplified model of real collective action, which can perform all stages simultaneously, in varying combinations. The ideation stage consists of generating ideas for possible actions, including topics such as commons-based peer production. Deliberation consists of discussing problems and proposed solutions, as occurs in social learning and the discourse of the public sphere. In decision-making, group members aggregate their individual preferences into a social preference for the entire group, as formalized in social choice theory. In the execution stage, once a decision has been agreed on, group members act, either complying with the group’s decision or, if some dissent and conflict remain, defecting or sanctioning defectors.

\section{Collective Action}
Much of the existing literature on collective action focuses on two questions. First, what are the conditions that lead to cooperation? And second, when is collective action effective?

\subsection{Cooperation}
Collective action depends on the cooperation of group members, in particular contributions of their resources. Olson's zero contribution thesis argues that cooperation in public goods settings is only possible in small groups or through coercion (Olson, 1965). When individuals can free-ride on the contributions of others without fear of punishment, the situation resembles a multiplayer prisoner’s dilemma. A rational egoist has an equilibrium solution of zero contribution. But cooperation does occur in the world. Experiments show that people often behave as Conditional cooperators, and willing punishers (Ostrom, 2000). Conditional cooperators are trusting when they expect that trust to be reciprocated. Willing punishers choose to punish norm violations even when the cost outweighs the benefits.

Why does cooperation occur? Real individuals are not always motivated by rational egoism. As Yochai Benkler writes, “there exist ranges of human experience in which the presence of monetary rewards is inversely related to the presence of other, social-psychological rewards (2002).” He cites examples including marriage, sex, and gift exchange. Ostrom (2000) proposes that the human deontic problem-solving system, allowing us to reason about norms, guilt, and shame has enabled us to adopt cooperative behaviors despite their apparent short-term irrationality. Ironically, these behaviors may be more rational than they seem when taking a long-term, large-scale perspective. In evolutionary models of a repeated prisoner’s dilemma, communities of trusting individuals can outperform less trusting individuals (Axelrod, 1997a). Ostrom suggests that the deontic problem-solving system allows humans to learn seemingly irrational cultural norms such as trust, and pass those norms on to future generations when they allow groups and societies to thrive.

\subsection{Collaboration}
While groups have access to a greater pool of resources than any of their individual members, some of those resources must be spent on communication and coordination, contributing to process loss (Steiner, 1972). Both organizational psychologists and economists have investigated when the benefits of collaboration outweigh the costs. 

(Hill, 1982)
Review of organizational psychology research on teams performing many types of tasks finds that groups typically perform better than individuals, while taking longer to find a solution. However, except in a few cases, statistical aggregates or high skilled individuals perform at least as well as groups. Exceptions were for complex tasks like crossword puzzles which no individual could solve on their own.

(Hill, 1982)
Process gain from capacity to learn from each other.
"This research confirms the belief that the performance of one exceptional individual can be superior to that of a committee (Davis, 1969rb), especially if the committee is trying to solve a complex problem and if the committee contains a number of low-ability members." Contrast to (Hong \& Page, 2004).

Informed by case studies of shared resources such as municipal water supplies, police departments, forests, and fisheries, Elinor Ostrom (2000; 2010) has proposed a set of design patterns that tend to appear in long-surviving, self-organized common pool resource governance.

\begin{description}
\item[Boundaries.]{Clear boundaries delineating who is and is not a member of a group enable the development of within-group reciprocity and trust.}
\item[Rules for appropriation and provision.]{Rules reduce uncertainty by defining the inputs, how much, when, how of resource use. congruence with local conditions. Such rules are not necessarily formal, but are adapted to local conditions.}
\item[Collective Choice Arrangements.]{When all individuals affected by rules are able to participate in creating them, rules are both better adapted to local conditions and have more legitimacy in the eyes of the group.}
\item[Monitoring of Users and Resources.]{Users select individuals to monitor both resources and users.}
\item[Graduated Sanctions.]{Sanctions for users who violate rules and norms begin light, but become more severe with repeated misconduct. Sanctions help to publicly reinforce trust that norms will be followed and what they are, as well as allow users who violated them to re-establish trust.}
\item[Conflict Resolution Mechanisms.]{Conflicts over interpretations of rules inevitably arise, and fast effective means of resolving those conflicts maintain trust.}
\item[Minimal Recognition of Rights.]{External authorities recognize the rights of the group and cannot be used as a threat to destroy the group.}
\item[Nested Enterprises.]{When resources exist at multiple scales, they are governed by nested organizations, each adapted to a particular scale.}
\end{description}

Ostrom also identifies common anti-patterns that pose a threat to sustained collective action by creating unpredictability, eroding trust, or creating rules at odds with local conditions.

\begin{enumerate}
\item{Migration}
\item{Government imposed rules}
\item{Rapid changes in technology}
\item{Transmission failure}
\item{Reliance on external aid}
\item{External aid disconnected from local knowledge and institutions}
\item{Corruption}
\item{Conflict between regimes}
\end{enumerate}

\subsection{Types of Collaboration}

In a process as complex as collective action, many factors might be important for an analysis. Hill (1982) suggests a two-dimensional framework based on interpersonal context and performance evaluation (Figure TODO). Interpersonal context describes how groups of individuals interact. Isolated individuals have no interaction, but their outputs might be aggregated, as with Galton's ox (1907). Coacting individuals interact freely and synchronously, as in a typical meeting. Dispersed individuals asynchronously, as is more typical of online collaborations (Benkler, 2002). Performance can be evaluated based on each individual, the best member's output, the union of all members output (e.g., brainstorming), or a single collaborative output. Ostrom (2000) also identified several factors that might be relevant to the functioning of a specific collective regime:

\begin{enumerate}
\item{Type of production and allocation functions}
\item{Predictability of resource flows}
\item{Relative scarcity of the good}
\item{Size of the group}
\item{Heterogeneity of the group}
\item{Dependence of the group on the good}
\item{Common understanding of the group}
\item{Size of the total collective benefit}
\item{Marginal contribution by one person to the collective good}
\item{Size of the temptation to free ride}
\item{Loss to cooperators when others do not cooperate}
\item{Having a choice of participating or not}
\item{Presence of leadership}
\item{Past experience and level of social capital}
\item{Autonomy to make binding rules}
\end{enumerate}
 
Discussions so far have considered collective action at a macro level. In order to understand the role of ICT in large-scale collective action, it is necessary to use a finer grained analysis. Smaller parts of the collective action process tend to be studied in different fields. For the purposes of this paper, idea generation, deliberation, social choice, and action (Figure TODO). Idea generation is studied in organizational psychology, deliberation in sociology and political science, social choice in economics and political science, and action in sociology, anthropology, public policy and epistemology. My focus is on deliberation, so this stage of the framework is further expanded to include both predictions of how actions will lead to outcomes and individual preferences over those outcomes. One depends  on only on information and reasoning, while the other requires discourse (Habermas, 1964) between humans, and might interact with ICT in very different ways (Geiger, 2009).

\begin{figure}
\centering
\includegraphics[width=4in]{images/fig-framework.pdf}
\caption{
Collective action framework.\label{fig:framework}
}
\end{figure}

\section{The Economics of Peer-Production}
The internet has enabled near-instantaneous, many-to-many communication at a previously unknown scale. The affordances of the internet are promising for large-scale collective action. Internet-enabled collaborations are novel for more reasons than their scale, they follow fundamentally different economics. Yochai Benkler (2002, 2006) labels this new form of economic production commons-based peer production, in contrast to more traditional forms of organization and production: firms, markets, and states (Coase, 1937; Ostrom, 2010). The new form is “commons-based” for two reasons. First, because outputs are contributed to the knowledge commons (a public good). Second, despite the non-rivalrous nature of the knowledge commons, there is incentive for free-riding and social loafing, analogous to the “tragedy of the commons” that occurs for common goods. The form is peer-produced because it is non-hierarchical: tasks are self-selected within a group of peers, rather than assigned from a superior to a subordinate. Benkler (2002) discusses examples including: NASA click workers, Wikipedia, the Google search engine, and the web forums Slashdot and Kuro5hin. Commons-based peer production faces the same motivational and organizational challenges as other forms of collective action, but offers both new resolutions to those challenges as well as potential advantages over other forms of production.

In addition to the usual motivations for non-rational-egoist behavior, commons-based peer production offers a unique solution to the problem of motivation: decomposability (Benkler, 2002). When tasks can be broken up into small pieces, each of those pieces might require very small amounts of motivation relative to tasks performed in a traditional firm. Furthermore, when those sub-tasks can be shared with a very large group, it is easier for individuals to identify the sub-tasks best matched to their particular level and type of motivation. Decomposability makes it possible for dispersed teams to collaborate on a problem (Hill, 1982). Dispersed interactions create additional coordination challenges: accreditation (quality control) and integration of outputs. There are many possible approaches to accreditation and integration: hierarchical, norms-based, or aggregation/averaging for example. Or, as in the case of peer review, these tasks can also be peer-produced. Peer-production of accreditation and integration is a key component of Benkler’s formulation of commons-based peer production. Using Hill’s classification (1982), commons-based peer production tasks use a group product evaluation criterion. Note that the dispersed “individuals” above could also be small, coacting sub-groups, allowing for a combination of dispersed and co-acting collaboration.

The need for accreditation and integration in peer-production suggests that it is not entirely non-rivalrous: if two incompatible outputs are produced by different sub-groups, at most one can be integrated into the groups final output. So while the ideation stage of peer-production is non-rivalrous, the decision-making stage is rivalrous. However, when the process of integration and accreditation is itself peer-produced, the final output is a hybrid: a rivalrous good produced through a non-rivalrous process. The dispersed decision-making process of accreditation and integration is a social learning process (discussed in more detail in a later section). Commons-based peer production is thus an example of collective intelligence that combines non-rivalrous peer production with social-learning-based accreditation and integration (Figure 2).

\begin{figure}
\centering
\includegraphics{images/fig-peer-intelligence.pdf}
\caption{
Commons-based peer production relies on social learning for
accreditation and integration. Collective intelligence relies on peer
production for ideation and preference aggregation.\label{fig:peer-intelligence}
}
\end{figure}

Benkler (2002) identifies the economic conditions that favor peer production. Specifically, he notes that peering must be more efficient than market-based solutions (Coase, 1937) and that the cost of enforcing contract or property rights must outweigh the benefit (Demsetz, 1974). When do these conditions occur? Benkler attributes the benefits of peer production partly to larger group with access to more resources, but primarily to allocation gains and information gains. He argues that, with the low cost of communication and storage, creativity is often the scarce resources, and that creative talent is variable and task-specific. The variability of creative work makes it difficult to allocate the right people to the right task. Peer production overcomes this difficulty by letting individuals self-assign. This benefit is amplified in the absence of property rights, which would otherwise limit individuals to working on tasks entirely within one firm. Benkler writes “The widely distributed model of information production will better identify who is the best person to produce a specific component of a project, all abilities and availability to work on the specific module within a specific time frame considered." The lack of property rights also allows any combination of collaborators to form a sub-group to work on a sub-task, allowing increased functional diversity (Hong \& Page, 2004).

The relative value of peer production also depends on the specifics of the task being performed. Benkler writes, "peer production is limited not by the total cost or complexity of a project, but by its modularity, granularity, and the cost of integration," (2002). In a later section, I will discuss insights on task complexity from collective intelligence and social learning that might help inform internet-enabled collective action. Similarly, the cost of integration depends both on organizational networks and on networks of trust relationships. Hierarchical organizations have bottlenecks (i.e., managers and information brokers) who increase the cost of integrating ideas from different parts of the network. Given the need for organizational networks to reflect task structure (Conway, 1968), the more interdependent a task is, the more interdependent the organizational network will need to be. Interdependence creates complexity, raising the cost of integration. This cost can be mitigated in the presence of trust, specifically by the ability to predict the behavior of other members, as reflected by many of Ostrom’s (2000) design patterns for self-organized collective action.

\section{Social Choice Theory}
One of the most fundamental challenges of collective action is the need to choose a single course of action when group members are in disagreement. This problem has been addressed by philosophers and mathematicians throughout history, and more recently by social choice theory, a subfield within microeconomics. Social choice focuses on the selection between alternatives/candidates/proposals. For this review, I will use the term “proposal.”

When members of a group disagree, one approach is to put the issue to a vote. In certain contexts, voting can be quite effective. Assuming a binary choice with a correct answer, and decision-makers who independently choose the correct answer with probability p, the Condorcet jury theorem (Condorcet, 1785) states that when p > ½, the probability of the majority choosing correctly approaches 1 as the number of decision-makers grows. While a promising result, the assumptions made by this theorem are somewhat artificial. Many important decisions are “wicked problems,” having no single correct answer (Hill, 1982; Anderson, 2006). Also, decision-makers are seldom independent (Hong \& Page, 2009), and rarely homogeneous (Anderson 2006; Hong \& Page 2004). I will return to these criticisms in later sections. A third difficulty forms the central focus of social choice theory: when more than two alternatives exist, there are many conflicting ways to compute a winner.

Simple majority and plurality voting are two straightforward voting methods which can give contradictory results. In plurality voting, the proposal with the most votes wins, even if it does not have a majority. In other words, it is possible for the majority of voters to disapprove of the winner. However, requiring a majority creates its own problems. When there are three proposals and no majority exists, supporters of the two less popular can join together behind one of their proposals allowing it to win, despite another option being more highly preferred ( Brandt et al., 2012).

More sophisticated approaches consider pairwise comparisons between proposals. For example, the Condorcet winner is the proposal that receives a majority of votes in pairwise contests against all other proposals (Condorcet, 1785; Brandt et al., 2012). It is difficult to argue against choosing the Condorcet winner, when such an alternative exists, but there is no guarantee that it will. The Condorcet paradox (Condorcet, 1785; Brandt et al., 2012) states that even when individual preferences are transitive, group preferences determined by pairwise votes can be intransitive. For example, if there are three alternatives (Rock, Paper, Scissors) it is possible that, in pairwise votes, Rock beats Scissors, Scissors beats Paper, and Paper beats Rock. In this example, none of the alternatives beat both of their competitors in pairwise votes. Similarly, while any choice between a finite set of proposals can be decomposed into a series of binary choices (i.e., option A or not, option B or not, …), such decompositions are path dependent, with the outcome depending on the order in which proposals are considered.

Voting methods can be formalized as social welfare functions in order to evaluate and compare them systematically (Arrow 1950; Brandt et al., 2012). Each voter’s i’s preferences form a total order $<_i$ over all proposals. Social choice theory typically considers voting methods which depend only on the set of all voter preferences ${<_i: i in V}$. This set is the preference profile. The purpose of the voting method is to map the profile into a single social preference representing the group. Ties are allowed, but in order to avoid the Condorcet paradox, the social preference must be at least weakly transitive. The social preference is thus represented by a weak order, and the voting system by a social welfare function mapping the profile to the social preference. Similarly, a social choice function maps each profile into a single winner (or set of winners in the case of a tie).

Using the above formalism, Arrow (1950) demonstrated that any social welfare function will be in some sense unfair. Specifically, Arrow’s impossibility theorem states that no social welfare function can satisfy all of the the following three fairness criteria:
Weak Pareto efficiency: if A is preferred to B in all individual preferences, then A is preferred to B in the social preference.
Independence of irrelevant alternatives: changing the position of any C within any individual preference will not change the order of A and B in the social preference.
No dictator: group preference is not entirely determined by one member of the group.
Social choice theory has thus focused primarily on identifying desirable properties of voting systems and cataloguing the properties satisfied by various systems.

\subsection{Voting Systems}
Social choice theorists have studied many voting methods. I will describe a few which are relevant to this prelim (Brandt et al., 2012).

Condorcet method. A majority vote is conducted for each pair of proposals. If any proposal wins against all others, it is the winner. Such a winner is not guaranteed to exist.

Dodgson’s method extends the Condorcet method. For each alternative, the Dodgson score is the total number of adjacent pairs in the profile that need to be re-ordered to make that alternative a Condorcet winner. If a Condorcet winner exists, its Dodgson score is 0 and it wins. Calculating the Dodgson winner is NP-hard.

Borda count. Each alternative receives a score: the total number of proposals less popular than it over all individuals. This score is its Borda count, and the proposal with the highest Borda count is the winner. This winner can be found in polynomial time.

Copeland rule. Majority votes are held between each pair of proposals. A proposal’s Copeland score is the number of pairwise elections won minus the number lost. The proposal with the highest score wins.

Ranked Pairs / Tideman method. Pairwise majority votes are held. The results are ranked in order of descending margin. In this order, the winner of each comparison is placed above the loser in the social preference, unless doing so would create an intransitive cycle. The proposal with the highest social welfare value wins. Tideman can be interpreted as a greedy approximation of minimizing the dissatisfaction of voters with the social preference (Meskanen \& Nurmi, 2006).

\subsection{Spatial Models}
A noteworthy class of social welfare functions represents proposals and voter preferences as points in some mathematical space, and are thus called spatial models. One benefit of this representation is that positions can be compared using mathematically defined distance measures.

The individual preferences within social choice theory can be compared using several distance measures. These measures can be used to define distance rationalizable voting systems, which seek to minimize the winner’s distance from some ideal position (Elkind \& Slinko, 2016) (e.g., Dodgson’s method minimizing the distance to a profile with a Condorcet winner).

The Kendall tau metric (Kendall, 1938; Brandt et al., 2012) defines the distance between two total orders (i.e., individual preferences) as the number of pairs for which the two orders disagree:

[Equation]

The Spearman correlation (Spearman, 1904) of two total orders is given by the linear (Pearson) correlation between the lists of rank positions. While Kendall tau takes only order into account, Spearman also takes into account the magnitude of rank difference:

[Equation]

An alternative approach to spatial modeling fixes voter preferences and seeks a dominant strategy for selecting a proposal with the highest chance of winning. Such a model can represent a political candidate choosing a platform based on their perception of the preferences of voters and other candidates. In the simplest models, voter preferences are represented as a continuous variable in one dimension (e.g., liberal-conservative). Davis et al. (1970) consider both single and multiple dimensional models. For single-peaked preferences in one dimension, the dominant strategy is the position of the median voter. For preferences with more than one peak, it is possible that no dominant strategy exists. For spatial models with multiple peaks or multiple dimensions, the best strategy can exhibit path dependence, depending on which order proposals are picked. Davis et al. also consider the influence of voter abstention on strategy, assuming that alternatives may lose votes to abstention for two reasons. First, voters may abstain if they are indifferent between two outcomes. Second, voters may abstain if they feel alienated from the political process and unable to influence the outcome. Under these assumptions, moderate positions can be effective at shifting extreme positions toward the center, and it is possible for an alternative to win over another with higher support if support for the majority position is more dispersed in preference space. In practice, voters’ ideal points in preference space are latent but can be inferred from behavioral signals such as past votes (Clinton \& Rivers, 2004).

Returning to the problem of aggregating preferences, the median can be useful even in multiple dimensions. The median can be generalized to multiple dimensions as the point which minimizes the sum of distances to all other points. As long as pairwise distances between voters form a median graph, a series of 3-way votes can efficiently find the median (Goel \& Lee, 2012; 2016). Furthermore, the median is either the Condorcet winner (if it exists) or a good approximation. Goel and Lee (2012) propose an efficient method to find an approximation of the generalized median. The Goel-Lee method chooses a triad of 3 voters at random, and asks each to vote between the preferences of the other two. All three are then required to vote for winning proposal in the next time they vote. The population converges to the generalized median in $O(n log^2 n)$ triads.

\section{Discourse, Deliberation, and Democracy}
While the paradoxes of social choice theory seem to bode ill for participatory decision-making at large scales, there is more to decision-making than voting. Voter preferences are not fixed, but influenced by public opinion and deliberation. The ability to change preference profiles through deliberation suggests the possibility of resolving conflicts. And the ability of the internet to enable discourse and deliberation at a large scale suggests it might make new forms of decision-making, collective intelligence, and collective action possible. Discourse, deliberation, and voting are distinct but intimately related components of participatory decision-making. Group members share information and opinions through discourse, persuade through deliberation, and aggregate preferences through votes.

\subsection{Democracy}
Democracy is delineated from other forms of collective action by universal participation without the need for actions to be universally supported. It relies on two institutions votes and talk (Anderson, 2006). Talk includes both the discourse of the public sphere as well as the deliberation of formal or and informal bodies. Votes are necessary both to identify and to give legitimacy to one of several competing proposals.

In contrast to authoritarian governance, there are several arguments for the advantages of democracy. Centralization limits the ability of decision-makers to use widely-dispersed information, while democracy enables collective intelligence (Hayek, 1945). Procedural arguments favor democracy as more fair, while epistemic arguments favor it as more effective (Anderson, 2006). Anderson gives three conditions necessary for democracy: 1. A matter of public interest, 2. Necessity for joint action, and 3. Reliance on the law. Because cooperation is required despite a lack of universal agreement, democracy relies on some level of coercion of dissenting group members through the law.

Talk (discourse and deliberation) plays several roles in democracy. At the ideation and deliberation stages of collective action, the  role of talk is to generate and evaluate ideas. This process consists of discourse within and communication between “multiple, cross-cutting organizations” (Anderson, 2006). In “strong democracy,” participation is emphasized over voting (Gonz\'alez-Bail\'on, 2010). By doing so, conflict resolution is shifted from coercion and sanctioning of dissent at the execution stage to building agreement at the deliberation stage. For democracy to function, members do not need to agree with the group’s decision, but they do need to cooperate. Dissent, by prompting deliberation, can secure the cooperation of dissenting individuals through “mutual accommodation” (Anderson, 2006).

\subsection{Discourse and the Networked Public Sphere}
As public discourse moves from older broadcast media and onto the internet, its context has changed. Yochai Benkler coined the term networked public sphere (Benkler, 2006) to refer to the unique affordances the internet offers for public discourse, building on sociological concept of the public sphere (Habermas, 1964). The public sphere refers to the social communication conducted by private individuals when they assemble into a public body, for example: newspapers, radio, and television.

The networked public sphere is notable for the affordances offered by the internet: scale, speed, decentralization, and low cost of speech (Benkler, 2002; 2006). The internet operates at a global scale, allows instantaneous publication, is difficult for any single entity to control, and allows the entire public the opportunity to speak without large investments of capital. However, the internet also faces challenges as a medium for pubic discourse, including: fragmentation, emergent centralization, authoritarian filtering, replacing traditional media’s role as a watchdog, and the digital divide.

The wide participation enabled by the large scale of the internet also creates the potential for fragmentation of the public sphere into isolated communities (Geiger, 2009; Benkler, 2006). There have been two common solutions for integrating the discourse of very large groups of people online. The first is algorithmic, for example: the Google search engine, which aggregates data from sources across the internet to gauge the quality of content (Benkler, 2006). However, algorithmic integration is insufficient for creating a public sphere because it is not discursive: running an algorithm is not a social communicative act between humans (Geiger, 2009). The second resolution is the use of technology to enable discursive interactions between large groups, such as reputation systems, peer review, structured posting privileges (Benkler, 2006). “Filtering, accreditation, synthesis, and salience are created through a system of peer review by information affinity groups, topical or interest based. These groups filter the observations and opinions of an enormous range of people and transmit those that pass local peer review to broader groups and ultimately to the polity more broadly (Geiger, 2009)." Such systems allow filtering and synthesis through trial-and-error rather than through careful planning, through evolution rather than engineering. Such systems are particularly applicable when errors can recovered from relatively easily.

The structure and protocols of the internet were designed to be decentralized (Baran, 1964), and while necessary for a decentralized sociotechnical system, decentralized architecture and protocols are not sufficient. Centralization can emerge within a decentralized framework due to social, organizational, and economic processes. In fact, the internet exhibits centralization on the levels of router connections and web links (Albert et al., 2000) as well as market share (Noam, 2003). However, this centralization differs from the centralization of traditional media in important ways. Small clusters of sites exceed the activity predicted by power-law distributions (Pennock, 2002). These overlapping topical and organizational clusters form a “filtering and transmission backbone" (Benkler, 2006). This backbone is bidirectional, allowing utterances from peripheral parts of the network to quickly reach central sites for amplification. This backbone also contains redundant paths not typical of more traditional media, allowing utterances many opportunities for both filtering and amplification. As long as communication is redundant and bidirectional, emergent centralization on the internet is not at odds with public discourse.

The existence of overlapping topical, organizational, and geographic clusters plays an important role in civic participation and discourse (Putnam, 2000; Anderson, 2006; Geiger, 2009), in part by counteracting fragmentation and centralization (Benkler, 2006). When individuals from different clusters interact, there is a potential for a clash of culture and norms. Norris and Inglehart (2009) describe four possible scenarios. In the L.A. effect, a dominant cluster exports its own cluster to others. In the Bangalore effect, cultures from different clusters mix and coexist. In the Taliban effect, conflicting cultures polarize against each other. Finally, in the firewall effect, different cultures simply ignore each other despite the ability to communicate. While the L.A. and Bangalore effects are conducive to a networked public sphere, the others are not. For ICT-enabled collective action, the implication is that the technology must facilitate sub-groups resolving conflict through communication, rather than through polarization or isolation.

\subsection{Deliberation}
Deliberation, in contrast to voting, is social communication intended to change the preferences of the participants (Gonz\'alez-Bail\'on et al., 2010). This might occur through social learning (Hill, 1982) or through changes in preferences created by the act of deliberation itself (Anderson, 2006). In other words, deliberation can alter preferences towards actions by altering the predicted outcomes of those actions, or by changing the preferences of the outcomes themselves (Figure 2).

In “strong democracy” there is universal participation in deliberation, not just voting (Gonz\'alez-Bail\'on et al., 2010). Deliberation can be classified on two axes: representation, and argumentation (Figure 3) (Ackerman \& Fishkin, 2002). An editorial is limited in representation and argumentation. A televised debate is limited in representation, but high on argumentation. A national poll is high on representation but low on argumentation. “Constitutional moments” when the population is widely debating a topic fall into the category of high representation and high argumentation, but have traditionally been infrequent and short-lived. Deliberative democracy requires both representation and argumentation, but the two have been difficult to achieve simultaneously, at least with traditional media. Examples of internet-based deliberation, such as Wikipedia (Benkler, 2006) and Slashdot (Gonz\'alez-Bail\'on et al., 2010; Benkler, 2006) have been able to achieve both.

\begin{figure}
\includegraphics{images/fig-deliberation.png}
\caption{Types of deliberation. Adapted from (Ackerman \& Fishkin, 2002).\label{fig:deliberation}}
\end{figure}

Deliberative democracy appeals to procedural arguments for democracy. However, the epistemic merits of deliberative democracy depend on context. Deliberating groups do well on “eureka problems,” in which solutions can be easily recognized once they are found, but less well on wicked problems (Gigone \& Hastie, 1997). When groups self-organize into homogeneous groups, deliberation can increase polarization (Schkade et al., 2007) thereby decreasing functional diversity, which is necessary for improved team performance (Hong \& Page 2004). Effective deliberation requires careful attention to both task type and the human tendency towards homophily.

\subsection{Consensus}
There are many types of consensus (DeTar, 2013). DeTar classifies these forms as to whether they have open membership, egalitarian, formal procedures, binding decisions.

\begin{description}
\item[Corporate (nemawashi).]{Consensus-building informally before formal decision-making. This version can be considered a type of deliberation.}
\item[Scientific.]{A preponderance of agreement among researchers.}
\item[Standards.]{A non-binding agreement between stakeholders.}
\item[Consociationalism / Factional.]{Underrepresented factions are given representation in a formal decision-making body, and all formal decisions must be passed by unanimous consent.}
\item[Mob.]{Emergent, unstructured coordination, such as flocking or rioting.}
\item[Assembly.]{Formal body with open membership. All members may or may not have veto power.}
\item[Affinity.]{Small-scale informal decision-making in a closed group. All members have veto power.}
\end{description}

Types of consensus: mere consensus, correct consensus (Zollman, 2012).

Studies of consensus in social and organizational psychology have typically focused on affinity consensus, categorically excluding formal process (Gentry, 1982). Findings suggest that affinity consensus requires more time than voting, but produces better solutions (Nemiroff \& King, 1975). When trained in affinity consensus, group members are more likely to generate new, emergent solutions combining the resources of many group members (Hall \& Williams, 1970). These findings suggest that epistemic arguments for democracy based on collective intelligence might better apply to consensus.
\begin{itemize}
\item{Avoid arguing for your own position.}
\item{Avoid win-lose stalemates in discussion.}
\item{Avoid changing your mind only in order to avoid conflict and to reach agreement and harmony.}
\item{Avoid conflict-reducing techniques such as majority vote, averaging, bargaining, coin flipping and the like.}
\item{View differences of opinion as both natural and helpful rather than as a hindrance in decision-making.}
\item{View initial agreement as suspect.}
\end{itemize}

While “consensus” connotes agreement, many groups using affinity consensus do not require unanimous agreement. Quakers, for instance, use consensus to seek the “Spirit of God” and the “sense of the meeting” (Gentry, 1982). So consensus implies recognition of the conclusion reached by a group, but not necessarily agreement with that conclusion.

\section{Conflict and Influence}
As groups grow in size, there are more individual preferences and more opportunities for conflict between those preferences. One of the challenges in large-scale collective action is how to resolve these conflicts. In representative democracy, focus is shifted from discourse to voting, 
Enabling scalability at the cost of civic participation and the risk of the Condorcet paradox. ICT-enabled peer production has been able to overcome scaling difficulties while maintaining (or growing) discourse and participation. And as seen in the previous section, conflict can be a sign of functional diversity that enable emergent solutions. But what are the elements of large-scale collective actions that are able to resolve conflict?

The successful resolution of conflict often requires trust and cooperation. In the simple example of the prisoner’s dilemma, the dominant strategy for a single round game is to defect rather than cooperate, despite this strategy yielding the outcome with lowest social welfare. However, in an evolutionary model with repeated games, communities can develop norms regarding trust, allowing them to cooperate, resolve conflict, and achieve higher social welfare (Axelrod, 1997a; Ostrom, 2000). "A norm exists in a given social setting to the extent that individuals usually act in a certain way and are often punished when seen not to be acting in this way." (Axelrod, 1997a). Many of Ostrom’s design principles for self-organized collective action concern trust and norms, such as clear group boundaries (to identify who the norms apply to) and graduated sanctions (to reinforce norms) (Ostrom, 2000). In addition to norms, communities can exhibit metanorms: norms regarding the enforcement of norms. When metanorms punish individuals for failing to punish transgressions, genetic algorithm simulations suggest that communities can converge to a state where transgressions are rare (Axelrod, 1997a). Internal enforcement, i.e., guilt and shame, also play an important role in influencing behavior. Guilt relies on an internalized sense of allowed behavior, while shame relies on “social proof”, actions being visibles to others (Axelrod 1997a).

While dominance hierarchies are not compatible with collective action, there are non-hierarchical forms of dominance which might be. Using “leveling mechanisms” such as public opinion, ridicule, and disobedience, some small human societies are effective at “keeping aggressive and dominating individuals in check” (Boehm et al., 1993). Leaders in such societies are often described as being “a first among equals.” It is not that dominance is non-existent in such societies, it is that it is non-hierarchical. “Reverse dominance hierarchies” use dominance to reduce inequality. Similarly, in “heterarchies” individuals are simultaneously subordinate and superordinate to many others, enabling the use of dominance for conflict resolution without creating a single hierarchy of power (Sharp, 1958; Tonkinson, 1988; Crumley, 1995). Not to be confused with scalar hierarchies (Crumley, 1995).

\section{Social Learning}
A crucial part of collective intelligence is the ability of group members to learn from each other. Agents receive different information and are each able to communicate with some subset of others. There are many types of social learning, depending on the task being learned, the type of interaction between group members, the network structure of who communicates with whom. Social learning has been extensively modeled both mathematically and using agent based models.

Social learning tasks can be roughly divided into types: simple and complex. Simple tasks have a single correct solution, while complex tasks have many locally-optimal solutions. Simple tasks have either no sub-tasks or tasks which can be solved independently, while complex tasks have interdependent sub-tasks. Agents in simple tasks receive statistically independent generated signals, while agents in complex tasks receive interpreted signals, information differing due to perspectives and heuristics (Hong \& Page, 2009).

In a typical simple social learning problem, agents receive a measurement of some true value with independent random noise. For example, Galton’s ox (Galton, 1907) could be a simple social learning problem if one assumes that errors in guessing are independent and effectively random. Condorcet jury theorem (Condorcet,). Such problems can be solved by repeated averaging of information with neighbors (DeGroot, 1974). This approach converges to the true value as long as the communication is regular: all individuals have influence on the same number of neighbors (Golub \& Jackson, 2012). When individuals have different influence, the process experiences “persuasion bias” and the noise of the most influential individuals is interpreted as signal. The speed of convergence also depends on the communication structure, specifically the second eigenvector of the interaction matrix, which quantifies the existence of bottlenecks in the network (Golub \& Jackson, 2012), with higher connectivity producing faster convergence (Zollman, 2010). In the somewhat more realistic “bounded confidence” model, agents average opinions with neighbors only if those opinions differ from their own by less than a “tolerance parameter” (according to a spatial model). In this model, moderately tolerant groups benefit from higher connectivity, while low-tolerance groups benefit from central individuals who can act as bridges (Zollman, 2012). While simple social learning tasks are relatively well-understood, they are not particularly good models for real-world problems. Most problems in life are complex.

Complex social learning problems can be modeled as optimization problems. Agents search a space of parameters for one that optimizes an objective function. In “rugged landscapes,” the objective function has many local maxima, making search by gradient ascent impractical. Such landscapes can be created using the NK model (Kauffman, 1987). In this model, states have N dimensions or loci, with each dimension having a finite number of possible values (e.g., 0 or 1 in the binary case). Associated with each locus is a function $F_i$ depending on that locus and $K$ others. The $F_i$ are randomly assigned values in $[0,1]$ for each possible value of locus $i$ and its $K$ neighbors. An objective function is created by averaging all of the $F_i$. By varying $K$, the ruggedness of the objective function can be tuned.

Agent-based models of complex social learning problems have addressed the role of network structure and social learning strategies in complex problems. Agents can employ a range of behavioral strategies in a social learning setting. In conformity-based strategies (Mason \& Watts, 2012), agents adopt the solution most popular among its neighbors. In best-neighbor strategies (Lazer \& Friedman, 2007; Grim et al. 2013), agents evaluate the solutions of their neighbors and adopt the best one. Models exhibit a tradeoff between exploration of new solutions and exploitation of known solutions depending on both network structure (Lazer \& Friedman, 2007) and social learning strategy (Barkoczi \& Galesic, 2016). Such a tradeoff is a characteristic of real-world complex problems (March, 1991). Sparsely connected networks result in parallel problem solving and greater functional diversity (Lazer \& Friedman, 2007). Conformity-based strategies also enable greater functional diversity by allowing popular but sub-optimal solutions to persist (Barkoczi \& Galesic, 2016). Combinations of network structure and learning strategy which balance exploration and exploitation yield the best long-term performance (Barkoczi \& Galesic, 2016).

In a real-world setting, the importance of network connectivity can be interpreted as the importance of intersecting and cross-cutting social groups (Anderson, 2006; Benkler 2006; Putnam, 2000). The importance of social learning strategy has implications for the effectiveness of discourse decision-making, which explores many new and existing solutions, versus voting which singles out the best existing solution. However, it is important to note that the social component of collective action is not simply a matter of exchanging information, but also a matter of building trust and mutual accommodation (Anderson, 2006), which are not reflected in current agent-based models.


