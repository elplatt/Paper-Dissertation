\documentclass[twocolumn,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{times}
\usepackage{geometry}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage[switch]{lineno}
\linenumbers

\newtheorem{definition}{Definition}
\newtheorem{property}{Property}
\newtheorem{claim}{Claim}

\DeclareMathOperator{\unif}{unif}
\DeclareMathOperator{\sample}{sample}
\DeclareMathOperator{\setcount}{count}
\DeclareMathOperator{\mode}{mode}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{geometry}
\geometry{left=1.5cm,right=1.5cm,top=2cm,bottom=2cm}
\setlength{\columnsep}{0.5cm}

\title{Supplementary Information: \\
Small interlocking groups improve mass deliberation\\in the presence of strong social influence}
\author{
%Edward L. Platt\\
%University of Michigan\\
%elplatt@umich.edu
%and
%Herminio Bodon\\
%Northwestern University\\
%HerminioBodon2020\\@u.northwestern.edu
%\and
%Daniel M. Romero\\
%University of Michigan\\
%drom@umich.edu
Authors Redacted \\
for \\
Double-Blind Peer-Review
}
\date{\today}

\begin{document}

\maketitle

\section{Simulation Procedure}
We begin with a network $(V,E_t)$. The vertices $V$ correspond to agents. The edges $E_t$ allow agents to exchange information with their immediate neighbors at time $t$.
Agents collaborate to find a solution $s$ from a space of solutions $\mathcal{S}$ that maximizes an objective function $Q(s)$.
We use binary strings of length $d$ as our solution space: $s \in \mathbb{Z}^d$.
At any one time $t$, each agent $v$ has exactly one preferred solution $s_{v,t}$.
We generate a tunably rugged objective function $Q(s)$ using an NK-Model \cite{kauffman_towards_1987} (see Section \ref{subsec:task}) with N=15, K=6, exp=8.

\section{Network Topologies}

We use networks to represent constraints on who talks to whom. Each agent is represented by a vertex, and two agents are able to interact when their vertices are connected by an edge. In this paper we are concerned with network deliberation, which takes place on interlock networks. Interlocks are composed of small cliques (i.e., pods) with some vertices belonging to multiple cliques. For the interlock networks in this paper, each vertex belongs to exactly one pod at a time, with pod membership periodically reassigned to achieve multiple membership. As a control, we also consider networks representing conventional deliberation.


\section{Learning Strategies}
\label{sec:learning}

% Exclude bitwise majority from paper
\iffalse

\subsection{Bitwise Majority}
Instead of evaluating entire solutions on their popularity, it is also possible to evaluate the popularity of each component of a solution, i.e., each bit in the bit string \cite{platt_network_2018}.
We refer to this strategy as {\em bitwise majority} social learning.
As with previous strategies, bitwise majority can result in ties for individual bits, which result in ties for the resulting full solution.

\begin{definition}
The bitwise majority strategy $\mathcal{L}_{bitwise}$ is defined as:
\begin{eqnarray}
S_i &=& \bigcup_{x \in S} \{x_i\} \\
\mathcal{L}_{bitwise}(S)
&=& \mode(S_1) \times \mode(S_2) \ldots \times \mode(S_d),
\end{eqnarray}
where $x_i$ is the $i$th element of the binary string $x$,
$S_i$ is a multiset, and $\mode(S)$ returns a set containing the mode or modes of $S$, and $\times$ is the Cartesian product.
\end{definition}
As with conform, the bitwise majority strategy does not incorporate any new information about solution quality.
Bitwise majority also has the notable property of being able to produce novel solutions that vary significantly from any previously seen.

% End of bitwise majority
\fi

\section{NK Model}
\label{subsec:task}
The NK Model \cite{kauffman_towards_1987} is an optimization problem particularly well-suited for modelling complex tasks. The model is used to create a fitness function $Q(s)$ over some discrete space $\mathcal{S}$, typically binary strings of a fixed length.
The model is parameterized by two variables.
The first, $N$, is the dimension of the solution space, i.e., the length of each binary string.
The second parameter, $K$, determines the ``ruggedness'' of the fitness function, i.e., the number of local maxima.
In effect, the $K$ parameter allows the complexity of the optimization problem to be tuned.
The ability to tune task complexity makes the NK model well-suited for studying the role of complexity in various settings.
The construction of an NK fitness function from a set of parameters is a stochastic process.
So particular values of $N$ and $K$ define a class of fitness functions, which can be sampled to produce a specific fitness function.

We now show the construction of the NK model fitness function.
A class of NK model fitness functions can be defined by a tuple of integer parameters
$(N, K)$ such that $N > 0$ and $0 \leq K < N$.
We begin by defining $N$ fitness contributions functions:
\begin{eqnarray}
q_i &:& \mathbb{Z}^{K+1} \rightarrow [0, 1].
\end{eqnarray}
The value of each $q_i(x)$ is chosen uniformly at random in the range $[0, 1]$ at the time the function is defined.
We also define $N$ projection operators $P_i$ which select $K+1$ bits from a length-$N$ bit string.
Each $P_i$ selects the bit at index $i$ and $K$ other indices, chosen uniformly at random at the time $P_i$ is constructed.
For a solution $s$, the $i$th fitness contribution is evaluated on the $K + 1$ bits selected by the $i$th projection: $q_i(P_i(s))$.
The value of the fitness function is the mean of all fitness contributions:
\begin{eqnarray}
Q(s) &=& \frac{1}{N}\sum_{i=1}^N q_i(P_i(s)).
\end{eqnarray}

The parameter $K$ alters the ruggedness of the fitness function by controlling the interdependence between the $q_i$.
When $K = 0$, each $q_i$ depends on a single unique index of $s$,
allowing the $q_i$ to be optimized independently.
In this case, $Q(s)$ has a single maximum: the global maximum.
However, for $K > 0$, two things happen: it becomes possible for each $q_i$ to have multiple local maxima, and some of the $q_i$ become coupled due to dependence on the same indices of $s$.
The result is that as $K$ increases, both the number of local maxima of $Q(s)$ \cite{weinberger_local_1991} and the difficulty of simultaneously optimizing the $q_i$ increase.
In other words, $Q$ becomes more rugged, and more complex.

The distribution of local maximum values is asymptotically normal for large $K$ \cite{weinberger_local_1991}.
When a skewed distribution is preferred, it is common to exponentiate the value of $Q(s)$ as a final step \cite{lazer_network_2007, barkoczi_social_2016, gomez_clustering_2019}.

\section{Supplemental Results}

Figures \ref{fig:results-frac-parallel} and \ref{fig:results-frac-fallback} show pairwise comparisons of solution quality between strategy/network settings. Figures \ref{fig:results-bn-parallel-dist}--\ref{fig:results-conf-fallback-dist} show the complete solution quality distributions for all settings.
Tables \ref{tab:t-instrat-fallback}--\ref{tab:t-innet-parallel} show the t-values and Bonferroni-corrected p-values for comparisons across networks and strategies.

\begin{figure}
    \label{fig:results-frac-parallel}
    \centering
    \includegraphics[width=3.33in]{fig-result-frac-parallel.eps}
\caption{Fraction of simulations in which the row condition outperforms the column condition. Results are shown for parallel individual learning. In the case of a tie, weight is divided evenly.}
\end{figure}

\begin{figure}
    \label{fig:results-frac-fallback}
    \centering
    \includegraphics[width=3.33in]{fig-result-frac-parallel.eps}
\caption{Fraction of simulations in which the row condition outperforms the column condition. Results are shown for fallback individual learning. In the case of a tie, weight is divided evenly.}
\end{figure}

\begin{figure}
    \label{fig:results-bn-parallel-dist}
    \centering
    \includegraphics[width=3.33in]{results-bn-parallel-dist.eps}
\caption{Solution quality distribution for best-neighbor strategy with parallel individual learning.}
\end{figure}
\begin{figure}
    \label{fig:results-cn-parallel-dist}
    \centering
    \includegraphics[width=3.33in]{results-cn-parallel-dist.eps}
\caption{Solution quality distribution for confident-neighbor strategy with parallel individual learning.}
\end{figure}
\begin{figure}
    \label{fig:results-conf-parallel-dist}
    \centering
    \includegraphics[width=3.33in]{results-conf-parallel-dist.eps}
\caption{Solution quality distribution for the conform strategy with parallel individual learning.}
\end{figure}

\begin{figure}
    \label{fig:results-bn-fallback-dist}
    \centering
    \includegraphics[width=3.33in]{results-bn-fallback-dist.eps}
\caption{Solution quality distribution for best-neighbor strategy with fallback individual learning.}
\end{figure}
\begin{figure}
    \label{fig:results-cn-fallback-dist}
    \centering
    \includegraphics[width=3.33in]{results-cn-fallback-dist.eps}
\caption{Solution quality distribution for confident-neighbor strategy with fallback individual learning.}
\end{figure}
\begin{figure}
    \label{fig:results-conf-fallback-dist}
    \centering
    \includegraphics[width=3.33in]{results-conf-fallback-dist.eps}
\caption{Solution quality distribution for the conform strategy with fallback individual learning.}
\end{figure}

\begin{table*}[]
    \label{tab:t-instrat-fallback}
    \centering
    \begin{tabular}{l|ll|ccc}
        Strategy & Net A & Net B & \overline{B - A} & t & p* \\
        \hline
Best Neighbor&Pref. Attach.&Small World&-8.70e-02&-1.33e+01&1.27e-35\\
Best Neighbor&Pref. Attach.&Long Path&-5.98e-02&-8.62e+00&1.51e-15\\
Best Neighbor&Pref. Attach.&Random Pod&-1.15e-02&-1.83e+00&4.01e+00\\
Best Neighbor&Small World&Pref. Attach.&8.70e-02&1.33e+01&1.27e-35\\
Best Neighbor&Small World&Long Path&2.72e-02&4.53e+00&3.88e-04\\
Best Neighbor&Small World&Random Pod&7.55e-02&1.18e+01&1.66e-28\\
Best Neighbor&Long Path&Pref. Attach.&5.98e-02&8.62e+00&1.51e-15\\
Best Neighbor&Long Path&Small World&-2.72e-02&-4.53e+00&3.88e-04\\
Best Neighbor&Long Path&Random Pod&4.83e-02&7.34e+00&2.69e-11\\
Best Neighbor&Random Pod&Pref. Attach.&1.15e-02&1.83e+00&4.01e+00\\
Best Neighbor&Random Pod&Small World&-7.55e-02&-1.18e+01&1.66e-28\\
Best Neighbor&Random Pod&Long Path&-4.83e-02&-7.34e+00&2.69e-11\\
\hline
Confident Neighbor&Pref. Attach.&Small World&-7.52e-02&-1.13e+01&2.94e-26\\
Confident Neighbor&Pref. Attach.&Long Path&2.39e-03&3.64e-01&4.30e+01\\
Confident Neighbor&Pref. Attach.&Random Pod&5.80e-02&8.88e+00&1.86e-16\\
Confident Neighbor&Small World&Pref. Attach.&7.52e-02&1.13e+01&2.94e-26\\
Confident Neighbor&Small World&Long Path&7.76e-02&1.21e+01&1.08e-29\\
Confident Neighbor&Small World&Random Pod&1.33e-01&1.92e+01&1.36e-68\\
Confident Neighbor&Long Path&Pref. Attach.&-2.39e-03&-3.64e-01&4.30e+01\\
Confident Neighbor&Long Path&Small World&-7.76e-02&-1.21e+01&1.08e-29\\
Confident Neighbor&Long Path&Random Pod&5.56e-02&8.50e+00&4.00e-15\\
Confident Neighbor&Random Pod&Pref. Attach.&-5.80e-02&-8.88e+00&1.86e-16\\
Confident Neighbor&Random Pod&Small World&-1.33e-01&-1.92e+01&1.36e-68\\
Confident Neighbor&Random Pod&Long Path&-5.56e-02&-8.50e+00&4.00e-15\\
\hline
Conform&Pref. Attach.&Small World&3.60e-02&6.78e+00&1.24e-09\\
Conform&Pref. Attach.&Long Path&-1.63e-01&-2.22e+01&2.25e-87\\
Conform&Pref. Attach.&Random Pod&-2.28e-01&-3.19e+01&9.08e-153\\
Conform&Small World&Pref. Attach.&-3.60e-02&-6.78e+00&1.24e-09\\
Conform&Small World&Long Path&-1.99e-01&-3.17e+01&1.59e-151\\
Conform&Small World&Random Pod&-2.64e-01&-4.43e+01&2.20e-236\\
Conform&Long Path&Pref. Attach.&1.63e-01&2.22e+01&2.25e-87\\
Conform&Long Path&Small World&1.99e-01&3.17e+01&1.59e-151\\
Conform&Long Path&Random Pod&-6.48e-02&-8.31e+00&1.79e-14\\
Conform&Random Pod&Pref. Attach.&2.28e-01&3.19e+01&9.08e-153\\
Conform&Random Pod&Small World&2.64e-01&4.43e+01&2.20e-236\\
Conform&Random Pod&Long Path&6.48e-02&8.31e+00&1.79e-14\\
\hline
    \end{tabular}
    \caption{Two-tailed paired t-values across networks, within strategies. Results are for fallback individual learning. For all rows, dof=999 and $p^*$ is the Bonferroni-corrected p-value with m=60.}
    \label{tab:my_label}
\end{table*}

\begin{table*}[]
    \label{tab:t-innet-fallback}
    \centering
    \begin{tabular}{l|ll|ccc}
        Network & Strategy A & Strategy B & \overline{B - A} & t & p* \\
        \hline
Pref. Attach.&Best Neighbor&Confident Neighbor&-6.43e-02&-9.39e+00&2.33e-18\\
Pref. Attach.&Best Neighbor&Conform&8.96e-02&1.19e+01&6.83e-29\\
Pref. Attach.&Confident Neighbor&Best Neighbor&6.43e-02&9.39e+00&2.33e-18\\
Pref. Attach.&Confident Neighbor&Conform&1.54e-01&2.06e+01&7.57e-77\\
Pref. Attach.&Conform&Best Neighbor&-8.96e-02&-1.19e+01&6.83e-29\\
Pref. Attach.&Conform&Confident Neighbor&-1.54e-01&-2.06e+01&7.57e-77\\
\hline
Small World&Best Neighbor&Confident Neighbor&-5.26e-02&-8.39e+00&9.70e-15\\
Small World&Best Neighbor&Conform&2.13e-01&3.52e+01&4.46e-175\\
Small World&Confident Neighbor&Best Neighbor&5.26e-02&8.39e+00&9.70e-15\\
Small World&Confident Neighbor&Conform&2.65e-01&4.45e+01&1.24e-237\\
Small World&Conform&Best Neighbor&-2.13e-01&-3.52e+01&4.46e-175\\
Small World&Conform&Confident Neighbor&-2.65e-01&-4.45e+01&1.24e-237\\
\hline
Long Path&Best Neighbor&Confident Neighbor&-2.12e-03&-3.42e-01&4.39e+01\\
Long Path&Best Neighbor&Conform&-1.37e-02&-1.71e+00&5.20e+00\\
Long Path&Confident Neighbor&Best Neighbor&2.12e-03&3.42e-01&4.39e+01\\
Long Path&Confident Neighbor&Conform&-1.16e-02&-1.44e+00&8.96e+00\\
Long Path&Conform&Best Neighbor&1.37e-02&1.71e+00&5.20e+00\\
Long Path&Conform&Confident Neighbor&1.16e-02&1.44e+00&8.96e+00\\
\hline
Random Pod&Best Neighbor&Confident Neighbor&5.18e-03&8.40e-01&2.41e+01\\
Random Pod&Best Neighbor&Conform&-1.27e-01&-1.64e+01&1.07e-51\\
Random Pod&Confident Neighbor&Best Neighbor&-5.18e-03&-8.40e-01&2.41e+01\\
Random Pod&Confident Neighbor&Conform&-1.32e-01&-1.67e+01&1.39e-53\\
Random Pod&Conform&Best Neighbor&1.27e-01&1.64e+01&1.07e-51\\
Random Pod&Conform&Confident Neighbor&1.32e-01&1.67e+01&1.39e-53\\
\hline
    \end{tabular}
    \caption{Two-tailed paired t-values across strategies, within networks. Results are for fallback individual learning. For all rows, dof=999 and $p^*$ is the Bonferroni-corrected p-value with m=60.}
    \label{tab:my_label}
\end{table*}

\begin{table*}[]
    \label{tab:t-instrat-parallel}
    \centering
    \begin{tabular}{l|ll|ccc}
        Strategy & Net A & Net B & \overline{B - A} & t & p* \\
    \hline
Best Neighbor&Pref. Attach.&Small World&-6.75e-02&-1.13e+01&2.48e-26\\
Best Neighbor&Pref. Attach.&Long Path&-4.24e-02&-6.78e+00&1.25e-09\\
Best Neighbor&Pref. Attach.&Random Pod&-8.14e-03&-1.32e+00&1.12e+01\\
Best Neighbor&Small World&Pref. Attach.&6.75e-02&1.13e+01&2.48e-26\\
Best Neighbor&Small World&Long Path&2.50e-02&4.25e+00&1.42e-03\\
Best Neighbor&Small World&Random Pod&5.93e-02&9.38e+00&2.54e-18\\
Best Neighbor&Long Path&Pref. Attach.&4.24e-02&6.78e+00&1.25e-09\\
Best Neighbor&Long Path&Small World&-2.50e-02&-4.25e+00&1.42e-03\\
Best Neighbor&Long Path&Random Pod&3.43e-02&5.36e+00&6.14e-06\\
Best Neighbor&Random Pod&Pref. Attach.&8.14e-03&1.32e+00&1.12e+01\\
Best Neighbor&Random Pod&Small World&-5.93e-02&-9.38e+00&2.54e-18\\
Best Neighbor&Random Pod&Long Path&-3.43e-02&-5.36e+00&6.14e-06\\
\hline
Confident Neighbor&Pref. Attach.&Small World&-4.49e-02&-7.20e+00&7.03e-11\\
Confident Neighbor&Pref. Attach.&Long Path&-5.03e-03&-7.65e-01&2.67e+01\\
Confident Neighbor&Pref. Attach.&Random Pod&2.61e-02&4.02e+00&3.74e-03\\
Confident Neighbor&Small World&Pref. Attach.&4.49e-02&7.20e+00&7.03e-11\\
Confident Neighbor&Small World&Long Path&3.99e-02&6.96e+00&3.80e-10\\
Confident Neighbor&Small World&Random Pod&7.10e-02&1.18e+01&1.98e-28\\
Confident Neighbor&Long Path&Pref. Attach.&5.03e-03&7.65e-01&2.67e+01\\
Confident Neighbor&Long Path&Small World&-3.99e-02&-6.96e+00&3.80e-10\\
Confident Neighbor&Long Path&Random Pod&3.11e-02&4.89e+00&7.03e-05\\
Confident Neighbor&Random Pod&Pref. Attach.&-2.61e-02&-4.02e+00&3.74e-03\\
Confident Neighbor&Random Pod&Small World&-7.10e-02&-1.18e+01&1.98e-28\\
Confident Neighbor&Random Pod&Long Path&-3.11e-02&-4.89e+00&7.03e-05\\
\hline
Conform&Pref. Attach.&Small World&3.67e-02&6.85e+00&7.73e-10\\
Conform&Pref. Attach.&Long Path&-1.73e-01&-2.40e+01&7.10e-99\\
Conform&Pref. Attach.&Random Pod&-2.77e-01&-4.08e+01&6.29e-213\\
Conform&Small World&Pref. Attach.&-3.67e-02&-6.85e+00&7.73e-10\\
Conform&Small World&Long Path&-2.09e-01&-3.46e+01&3.46e-171\\
Conform&Small World&Random Pod&-3.14e-01&-5.68e+01&1.63e-313\\
Conform&Long Path&Pref. Attach.&1.73e-01&2.40e+01&7.10e-99\\
Conform&Long Path&Small World&2.09e-01&3.46e+01&3.46e-171\\
Conform&Long Path&Random Pod&-1.04e-01&-1.43e+01&8.55e-41\\
Conform&Random Pod&Pref. Attach.&2.77e-01&4.08e+01&6.29e-213\\
Conform&Random Pod&Small World&3.14e-01&5.68e+01&1.63e-313\\
Conform&Random Pod&Long Path&1.04e-01&1.43e+01&8.55e-41\\
    \hline
    \end{tabular}
    \caption{Two-tailed paired t-values across networks, within strategies. Results are for parallel individual learning. For all rows, dof=999 and $p^*$ is the Bonferroni-corrected p-value with m=60.}
    \label{tab:my_label}
\end{table*}

\begin{table*}[]
    \label{tab:t-innet-parallel}
    \centering
    \begin{tabular}{l|ll|ccc}
        Network & Strategy A & Strategy B & \overline{B - A} & t & p* \\
    \hline
Pref. Attach.&Best Neighbor&Confident Neighbor&-3.78e-02&-5.94e+00&2.39e-07\\
Pref. Attach.&Best Neighbor&Conform&2.00e-01&2.77e+01&3.28e-124\\
Pref. Attach.&Confident Neighbor&Best Neighbor&3.78e-02&5.94e+00&2.39e-07\\
Pref. Attach.&Confident Neighbor&Conform&2.38e-01&3.40e+01&1.67e-167\\
Pref. Attach.&Conform&Best Neighbor&-2.00e-01&-2.77e+01&3.28e-124\\
Pref. Attach.&Conform&Confident Neighbor&-2.38e-01&-3.40e+01&1.67e-167\\
\hline
Small World&Best Neighbor&Confident Neighbor&-1.52e-02&-2.74e+00&3.80e-01\\
Small World&Best Neighbor&Conform&3.05e-01&5.30e+01&1.25e-290\\
Small World&Confident Neighbor&Best Neighbor&1.52e-02&2.74e+00&3.80e-01\\
Small World&Confident Neighbor&Conform&3.20e-01&5.89e+01&0.00e+00\\
Small World&Conform&Best Neighbor&-3.05e-01&-5.30e+01&1.25e-290\\
Small World&Conform&Confident Neighbor&-3.20e-01&-5.89e+01&0.00e+00\\
\hline
Long Path&Best Neighbor&Confident Neighbor&-3.88e-04&-6.64e-02&5.68e+01\\
Long Path&Best Neighbor&Conform&7.02e-02&9.34e+00&3.64e-18\\
Long Path&Confident Neighbor&Best Neighbor&3.88e-04&6.64e-02&5.68e+01\\
Long Path&Confident Neighbor&Conform&7.06e-02&9.15e+00&1.83e-17\\
Long Path&Conform&Best Neighbor&-7.02e-02&-9.34e+00&3.64e-18\\
Long Path&Conform&Confident Neighbor&-7.06e-02&-9.15e+00&1.83e-17\\
\hline
Random Pod&Best Neighbor&Confident Neighbor&-3.59e-03&-5.46e-01&3.51e+01\\
Random Pod&Best Neighbor&Conform&-6.84e-02&-9.54e+00&6.11e-19\\
Random Pod&Confident Neighbor&Best Neighbor&3.59e-03&5.46e-01&3.51e+01\\
Random Pod&Confident Neighbor&Conform&-6.48e-02&-8.96e+00&9.43e-17\\
Random Pod&Conform&Best Neighbor&6.84e-02&9.54e+00&6.11e-19\\
Random Pod&Conform&Confident Neighbor&6.48e-02&8.96e+00&9.43e-17\\
    \hline
    \end{tabular}
    \caption{Two-tailed paired t-values across strategies, within networks. Results are for parallel individual learning. For all rows, dof=999 and $p^*$ is the Bonferroni-corrected p-value with m=60.}
    \label{tab:my_label}
\end{table*}

\bibliography{references}
\bibliographystyle{plain}

\end{document}
